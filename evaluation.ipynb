{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb936db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score\n",
    "import math\n",
    "from LAF import DBSCAN\n",
    "from LAF import DBSCANPP\n",
    "\n",
    "\n",
    "exp_ds_name = \"MS_50k\"\n",
    "alpha_for_laf_dbscan, alpha_for_laf_dbscanpp = 1.5, 1.0\n",
    "dbscanpp_p_delta = 0.2\n",
    "num_sample = 50000 \n",
    "minPts = 5 \n",
    "eps_cos_dist = 0.55\n",
    "\n",
    "print(\"=============== Parameters ========================\")\n",
    "print(\"exp_ds_name: {}\".format(exp_ds_name), flush=True)\n",
    "print(\"num_sample: {}\".format(num_sample), flush=True)\n",
    "print(\"eps_cos_dist: {}, minPts: {}\".format(eps_cos_dist, minPts), flush=True)\n",
    "print(\"alpha_for_laf_dbscan: {}, alpha_for_laf_dbscan++: {}\".format(alpha_for_laf_dbscan, alpha_for_laf_dbscanpp), flush=True)\n",
    "print(\"delta for DBSCAN++: {}\".format(dbscanpp_p_delta), flush=True)\n",
    "print(\"====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd9417",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "workdir = \"./prediction\"\n",
    "ds_root = \"./ds\"\n",
    "test_ds_path = os.path.join(\n",
    "    ds_root, \"{}.test.npy\".format(exp_ds_name)\n",
    ")\n",
    "print(\"Loaded test data from {}\".format(test_ds_path), flush=True)\n",
    "test_data_points = np.load(test_ds_path)\n",
    "    \n",
    "if test_data_points.dtype != np.float32:\n",
    "    test_data_points = test_data_points.astype(np.float32)\n",
    "\n",
    "points = test_data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b3106",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "def load_estimator_prediction():\n",
    "    test_res_arr = np.load(\"{}/{}_eps_{:.2f}_tau_{}.output\".format(workdir, exp_ds_name, eps_cos_dist, minPts))\n",
    "    return test_res_arr\n",
    "\n",
    "def cosDist2eucDist(cos_dist: float, scale_factor: float):\n",
    "  return math.sqrt(2 * (scale_factor**2) * cos_dist)\n",
    "\n",
    "# DBSCAN++ needs the equivalent Euclidean distance eps as it only supports that distance metric.\n",
    "# Same to DBSCAN/LAF-DBSCAN/LAF-DBSCAN++ as they are all implemented based on the codebase of DBSCAN++.\n",
    "euc_eps_for_dbscanpp = cosDist2eucDist(eps_cos_dist, 1)\n",
    "test_res_arr = load_estimator_prediction()\n",
    "pred_num_neighbors = test_res_arr[:, 0]\n",
    "\n",
    "def run_original_DBSCAN(points, euc_dist_eps, minPts): \n",
    "    dbscan_instance = DBSCAN(eps=euc_dist_eps, minPts=minPts)\n",
    "    start = time.time()\n",
    "    clusters_gt = dbscan_instance.fit_predict(points, cluster_outliers=False)\n",
    "    time_gt = time.time() - start\n",
    "    print(\"Elapsed time (DBSCAN): {} s\".format(time_gt), flush=True)\n",
    "    c = Counter(clusters_gt)\n",
    "    print(\"#clusters:\", len(c), flush=True)\n",
    "    return clusters_gt, time_gt, dbscan_instance\n",
    "\n",
    "def run_LAF_DBSCAN(dbscan_instance, points, pred_num_neighbors, clusters_gt, alpha=alpha_for_laf_dbscan):\n",
    "    signature = \"LAF-DBSCAN, alpha={:.2f}\".format(alpha)\n",
    "    relaxed_thresh = dbscan_instance.minPts * alpha\n",
    "    \n",
    "    start = time.time()\n",
    "    clusters_laf_dbscan, num_pred_core_pts, num_real_core_pts = \\\n",
    "        dbscan_instance.fit_predict_with_card_est_with_postproc(\n",
    "            points, \n",
    "            pred_num_neighbors, pred_core_minPts=relaxed_thresh, \n",
    "            cluster_outliers=False\n",
    "        )\n",
    "    time_laf_dbscan = time.time() - start\n",
    "    \n",
    "    print(\"Elapsed time ({}): {} s\".format(signature, time_laf_dbscan), flush=True)\n",
    "    c = Counter(clusters_laf_dbscan)\n",
    "    print(\"#clusters:\", len(c), flush=True)\n",
    "    print(\"[%s] ARI: %f \" % (signature, adjusted_rand_score(clusters_laf_dbscan, clusters_gt)), flush=True)\n",
    "    print(\"[%s] AMI: %f \" % (signature, adjusted_mutual_info_score(clusters_laf_dbscan, clusters_gt)), flush=True)\n",
    "\n",
    "    return clusters_laf_dbscan, time_laf_dbscan, num_pred_core_pts, num_real_core_pts\n",
    "\n",
    "def run_DBSCANpp(points, euc_dist_eps, minPts, init_method, clusters_gt, **kwargs):\n",
    "    # DBSCAN++ with dynamic sample fraction based on the #predicted_core_points of LAF-DBSCAN.\n",
    "    sample_fraction = float(kwargs['num_pred_core_pts']) / len(points) + kwargs['p_delta']\n",
    "    sample_fraction = min(sample_fraction, 1.0)\n",
    "    signature = \"DBSCAN++, dynamic p={:.4f}\".format(sample_fraction)\n",
    "    print(\"sample fraction (p): {} , init_method: {}\".format(sample_fraction, init_method), flush=True)\n",
    "\n",
    "    dbscanpp_instance = DBSCANPP(p=sample_fraction, eps_density=euc_dist_eps, eps_clustering=euc_dist_eps, minPts=minPts)\n",
    "\n",
    "    start = time.time()\n",
    "    clusters_dbscanpp = dbscanpp_instance.fit_predict(points, init=init_method, cluster_outliers=False)\n",
    "    time_dbscanpp = time.time() - start\n",
    "    print(\"Elapsed time ({}): {} s\".format(signature, time_dbscanpp), flush=True)\n",
    "\n",
    "    c = Counter(clusters_dbscanpp)\n",
    "    print(\"#clusters:\", len(c), flush=True)\n",
    "    print(\"[%s] ARI: %f .\" % (signature, adjusted_rand_score(clusters_dbscanpp, clusters_gt)), flush=True)\n",
    "    print(\"[%s] AMI: %f .\" % (signature, adjusted_mutual_info_score(clusters_dbscanpp, clusters_gt)), flush=True)\n",
    "    \n",
    "    return  clusters_dbscanpp, time_dbscanpp, dbscanpp_instance\n",
    "\n",
    "def run_LAF_DBSCANpp(dbscanpp_instance, points, pred_num_neighbors, clusters_gt, init_method, alpha=alpha_for_laf_dbscanpp):\n",
    "    signature = \"LAF-DBSCAN++, alpha={:.2f}, dynamic p={:.4f}\".format(alpha, dbscanpp_instance.p)\n",
    "    relaxed_thresh = dbscanpp_instance.minPts * alpha\n",
    "\n",
    "    start = time.time()\n",
    "    clusters_laf_dbscanpp = dbscanpp_instance.fit_predict_with_card_est_with_postproc(\n",
    "        points, \n",
    "        pred_num_neighbors, pred_core_minPts=relaxed_thresh, \n",
    "        init=init_method, cluster_outliers=False\n",
    "    )\n",
    "    time_laf_dbscanpp = time.time() - start\n",
    "    print(\"Elapsed time ({}): {} s\".format(signature, time_laf_dbscanpp), flush=True)\n",
    "\n",
    "    c = Counter(clusters_laf_dbscanpp)\n",
    "    print(\"#clusters:\", len(c), flush=True)\n",
    "    print(\"[%s] ARI: %f\" % (signature, adjusted_rand_score(clusters_laf_dbscanpp, clusters_gt)), flush=True)\n",
    "    print(\"[%s] AMI: %f\" % (signature, adjusted_mutual_info_score(clusters_laf_dbscanpp, clusters_gt)), flush=True)\n",
    "\n",
    "    return clusters_laf_dbscanpp, time_laf_dbscanpp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25b832",
   "metadata": {},
   "source": [
    "### Run and evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_gt, time_gt, dbscan_instance = \\\n",
    "    run_original_DBSCAN(points, euc_eps_for_dbscanpp, minPts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_laf_dbscan, time_laf_dbscan, num_pred_core_pts, num_real_core_pts = \\\n",
    "    run_LAF_DBSCAN(dbscan_instance, points, pred_num_neighbors, clusters_gt, alpha_for_laf_dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_method = 'uniform'\n",
    "clusters_dbscanpp, time_dbscanpp, dbscanpp_instance = \\\n",
    "    run_DBSCANpp(points, euc_eps_for_dbscanpp, minPts, init_method, clusters_gt,\n",
    "                p_delta = dbscanpp_p_delta, num_pred_core_pts=num_pred_core_pts \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bae5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_laf_dbscanpp, time_laf_dbscanpp = \\\n",
    "    run_LAF_DBSCANpp(dbscanpp_instance, points, pred_num_neighbors, clusters_gt, init_method, alpha_for_laf_dbscanpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c93549",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_laf_dbscan = adjusted_rand_score(clusters_gt, clusters_laf_dbscan)\n",
    "ami_laf_dbscan = adjusted_mutual_info_score(clusters_gt, clusters_laf_dbscan)\n",
    "ari_dbscanpp = adjusted_rand_score(clusters_gt, clusters_dbscanpp)\n",
    "ami_dbscanpp = adjusted_mutual_info_score(clusters_gt, clusters_dbscanpp)\n",
    "ari_laf_dbscanpp = adjusted_rand_score(clusters_gt, clusters_laf_dbscanpp)\n",
    "ami_laf_dbscanpp = adjusted_mutual_info_score(clusters_gt, clusters_laf_dbscanpp)\n",
    "\n",
    "scores_and_time = [\n",
    "    (\"groundtruth\", \"-\", \"-\", time_gt), \n",
    "    (\"DBSCAN++\", ari_dbscanpp, ami_dbscanpp, time_dbscanpp), \n",
    "    (\"LAF-DBSCAN\", ari_laf_dbscan, ami_laf_dbscan, time_laf_dbscan),\n",
    "    (\"LAF-DBSCAN++\", ari_laf_dbscanpp, ami_laf_dbscanpp, time_laf_dbscanpp), \n",
    "]\n",
    "print(\"================= Evalution scores ======================\\n\")\n",
    "print(pd.DataFrame(scores_and_time, columns=[\"method\", \"ARI\", \"AMI\", \"time\"]))\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117fe86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
